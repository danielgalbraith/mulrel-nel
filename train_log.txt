load conll at data/generated/test_train_data/
load csv
process coref
load conll
create model
word voca size 492408
snd word voca size 60862
{'args': Namespace(ctx_window=100, dev_f1_change_lr=0.915, df=0.5, dropout_rate=0.3, eval_after_n_epochs=5, hid_dims=100, keep_ctx_ent=4, keep_p_e_m=4, learning_rate=0.0001, margin=0.01, mode='train', model_path='', mulrel_type='ment-norm', n_cands_before_rank=30, n_epochs=200, n_loops=10, n_not_inc=10, n_rels=5, prerank_ctx_window=50, print_incorrect=False, print_rel=False, snd_local_ctx_window=6, tok_top_n=25),
 'df': 0.5,
 'dr': 0.3,
 'emb_dims': 300,
 'entity_embeddings': array([[ 0.06      , -0.075     ,  0.014     , ...,  0.083     ,
        -0.02      , -0.031     ],
       [-0.1       ,  0.058     ,  0.041     , ..., -0.075     ,
         0.089     , -0.047     ],
       [ 0.014     ,  0.062     ,  0.028     , ..., -0.026     ,
         0.06      , -0.068     ],
       ...,
       [ 0.014     ,  0.018     , -0.025     , ...,  0.019     ,
        -0.043     , -0.057     ],
       [ 0.001     , -0.044     ,  0.149     , ...,  0.037     ,
         0.005     ,  0.02      ],
       [-0.00758579, -0.00171364,  0.03234197, ...,  0.01505074,
        -0.02316106, -0.04260057]]),
 'entity_voca': <nel.vocabulary.Vocabulary object at 0x7fcf7bfd9ba8>,
 'freeze_embs': True,
 'hid_dims': 100,
 'margin': 0.01,
 'mulrel_type': 'ment-norm',
 'n_loops': 10,
 'n_rels': 5,
 'snd_word_embeddings': array([[ 0.2587    ,  0.23414   ,  0.17771   , ..., -0.42938   ,
        -0.48392   ,  0.60828   ],
       [ 0.15139   , -0.20729   , -0.3755    , ...,  0.1377    ,
         0.075059  , -0.27191   ],
       [ 0.25826   ,  0.23759   ,  0.21491   , ...,  0.6305    ,
         0.04818   , -0.45594   ],
       ...,
       [ 0.82401   , -0.15707   ,  0.29586   , ...,  0.44211   ,
        -0.17721   ,  0.13085   ],
       [ 1.1634    , -1.1471    , -0.53949   , ...,  0.41932   ,
         0.99353   , -0.59911   ],
       [ 0.22418612, -0.28881808,  0.13854355, ...,  0.19310516,
        -0.07767657, -0.14481587]]),
 'snd_word_voca': <nel.vocabulary.Vocabulary object at 0x7fcfe2003518>,
 'tok_top_n': 25,
 'word_embeddings': array([[ 8.00780000e-02,  1.04980000e-01,  4.98050000e-02, ...,
         3.66200000e-03,  4.76070000e-02, -6.88480000e-02],
       [ 7.03120000e-02,  8.69140000e-02,  8.78910000e-02, ...,
        -4.76070000e-02,  1.44650000e-02, -6.25000000e-02],
       [ 2.60010000e-02, -1.89200000e-03,  1.85547000e-01, ...,
        -1.21582000e-01,  2.21680000e-01, -2.19730000e-02],
       ...,
       [ 2.81250000e-01, -2.13620000e-02,  1.72120000e-02, ...,
         4.02830000e-02,  2.14844000e-01,  2.00195000e-01],
       [ 1.86770000e-02,  1.28906000e-01,  5.17580000e-02, ...,
         2.25830000e-02,  2.15820000e-01,  3.36910000e-02],
       [-2.25727598e-04, -1.01302859e-03, -1.04770562e-02, ...,
        -2.76348449e-02,  6.10916865e-02,  3.80460705e-02]]),
 'word_voca': <nel.vocabulary.Vocabulary object at 0x7fcf7f73f908>}
--- create model ---
prerank model
main model
create new model
---------------- model config -----------------
freeze_local False
ent_top_n 1000
freeze_embs True
use_stargmax False
df 0.5
margin 0.01
use_local_only False
training True
n_loops 10
hid_dims 100
use_local True
tok_top_n 25
use_pad_ent True
oracle False
_coh_ctx_vecs None
n_rels 5
emb_dims 300
ent_ent_comp bilinear
ctx_comp bow
ew_hid_dims 300
first_head_uniform False
dr 0.3
max_dist 1000
mode ment-norm
-----------------------------------------------
training...
{'lr': 0.0001, 'n_epochs': 200}
extracting training data
222
211
288
108
112
105
182
105
recall 1.0
#train docs 953
277
recall 0.9730745147150908
aida-A #dev docs 218
108
114
recall 0.9828316610925306
aida-B #dev docs 232
recall 0.9847560975609756
msnbc #dev docs 20
recall 0.9436038514442916
aquaint #dev docs 50
recall 0.9066147859922179
ace2004 #dev docs 35
recall 0.9169804554419939
clueweb #dev docs 320
recall 0.923418095801301
wikipedia #dev docs 318
creating optimizer
epoch 0 total loss 21.89522614834818 0.022975053670879517
epoch 1 total loss 0.9901209074570545 0.0010389516342676332
epoch 2 total loss 0.6161458213476863 0.0006465328660521367
epoch 3 total loss 0.5694772691700223 0.0005975627168625627
epoch 4 total loss 0.5508390455933636 0.0005780052944316512
aida-A micro F1: 0.831437219496921
aida-B micro F1: 0.8231884057971014
msnbc micro F1: 0.936495791889824
aquaint micro F1: 0.8797202797202797
ace2004 micro F1: 0.8772635814889336
clueweb micro F1: 0.7574559827524255
wikipedia micro F1: 0.7347089712299385
att_mat_diag tensor(17.3886, device='cuda:0')
tok_score_mat_diag tensor(17.6211, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(13.0479, device='cuda:0') tensor(1.1219, device='cuda:0')
relations tensor([18.3286,  1.1348,  1.1165,  1.1291,  1.1384], device='cuda:0')
tensor([[0.0000, 0.5288, 0.5707, 0.5605, 0.5415],
        [0.5288, 0.0000, 0.3423, 0.3438, 0.3395],
        [0.5707, 0.3423, 0.0000, 0.3387, 0.3694],
        [0.5605, 0.3438, 0.3387, 0.0000, 0.3574],
        [0.5415, 0.3395, 0.3694, 0.3574, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([1.7869, 1.3756, 1.3659, 1.4279, 1.4251], device='cuda:0')
tensor([[0.0000, 0.9854, 0.9820, 0.9803, 0.9798],
        [0.9854, 0.0000, 1.0023, 1.0009, 1.0015],
        [0.9820, 1.0023, 0.0000, 1.0026, 1.0016],
        [0.9803, 1.0009, 1.0026, 0.0000, 1.0017],
        [0.9798, 1.0015, 1.0016, 1.0017, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 5 total loss 0.5078035846818238 0.0005328474130974017
epoch 6 total loss 0.4938781878646523 0.000518235244349058
epoch 7 total loss 0.45636144839011195 0.00047886825644292963
epoch 8 total loss 0.43009499254992534 0.0004513063930219573
epoch 9 total loss 0.42062766222574055 0.00044137215343729335
aida-A micro F1: 0.8865462895313642
aida-B micro F1: 0.9050167224080268
msnbc micro F1: 0.9334353481254781
aquaint micro F1: 0.8727272727272728
ace2004 micro F1: 0.8893360160965794
clueweb micro F1: 0.7605102407473949
wikipedia micro F1: 0.7668071888173952
att_mat_diag tensor(17.4207, device='cuda:0')
tok_score_mat_diag tensor(17.7431, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(16.1051, device='cuda:0') tensor(1.2999, device='cuda:0')
relations tensor([19.0873,  2.0192,  2.0036,  2.0129,  2.0259], device='cuda:0')
tensor([[0.0000, 0.5465, 0.5750, 0.5651, 0.5561],
        [0.5465, 0.0000, 0.2311, 0.2331, 0.2290],
        [0.5750, 0.2311, 0.0000, 0.2280, 0.2499],
        [0.5651, 0.2331, 0.2280, 0.0000, 0.2418],
        [0.5561, 0.2290, 0.2499, 0.2418, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([3.0371, 2.5910, 2.6526, 2.6741, 2.7223], device='cuda:0')
tensor([[0.0000, 0.8090, 0.7987, 0.8137, 0.8089],
        [0.8090, 0.0000, 0.9950, 0.9964, 0.9876],
        [0.7987, 0.9950, 0.0000, 0.9901, 0.9940],
        [0.8137, 0.9964, 0.9901, 0.0000, 0.9950],
        [0.8089, 0.9876, 0.9940, 0.9950, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 10 total loss 0.3780002318407014 0.0003966424258559301
epoch 11 total loss 0.3894246960912824 0.0004086303211870749
epoch 12 total loss 0.35572547928222775 0.0003732691283129357
epoch 13 total loss 0.35479639747177316 0.0003722942260983979
epoch 14 total loss 0.3229438481591842 0.00033887077456367705
aida-A micro F1: 0.8773614445256237
aida-B micro F1: 0.8816053511705686
msnbc micro F1: 0.9349655700076511
aquaint micro F1: 0.8923076923076925
ace2004 micro F1: 0.8893360160965794
clueweb micro F1: 0.773895077254761
wikipedia micro F1: 0.7588196139338806
att_mat_diag tensor(17.4332, device='cuda:0')
tok_score_mat_diag tensor(17.7473, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(18.7096, device='cuda:0') tensor(1.3114, device='cuda:0')
relations tensor([19.5063,  2.5338,  2.5219,  2.5250,  2.5430], device='cuda:0')
tensor([[0.0000, 0.5771, 0.6022, 0.5923, 0.5859],
        [0.5771, 0.0000, 0.2053, 0.2075, 0.2028],
        [0.6022, 0.2053, 0.0000, 0.2018, 0.2217],
        [0.5923, 0.2075, 0.2018, 0.0000, 0.2144],
        [0.5859, 0.2028, 0.2217, 0.2144, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([4.0088, 3.4744, 3.5338, 3.5046, 3.6023], device='cuda:0')
tensor([[0.0000, 0.6891, 0.6899, 0.7091, 0.6954],
        [0.6891, 0.0000, 0.9274, 0.9437, 0.8889],
        [0.6899, 0.9274, 0.0000, 0.9004, 0.9252],
        [0.7091, 0.9437, 0.9004, 0.0000, 0.9342],
        [0.6954, 0.8889, 0.9252, 0.9342, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 15 total loss 0.3411263737266381 0.0003579500248967871
epoch 16 total loss 0.3353388315263146 0.00035187705301816853
epoch 17 total loss 0.30976314562633434 0.00032504002689017245
epoch 18 total loss 0.3142389174977325 0.00032973653462511275
epoch 19 total loss 0.2920513587396272 0.00030645473110139265
aida-A micro F1: 0.9009497964721844
aida-B micro F1: 0.905685618729097
msnbc micro F1: 0.9319051262433052
aquaint micro F1: 0.8951048951048951
ace2004 micro F1: 0.89738430583501
clueweb micro F1: 0.7784764642472153
wikipedia micro F1: 0.7685822054581761
att_mat_diag tensor(17.4246, device='cuda:0')
tok_score_mat_diag tensor(17.6989, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(21.0621, device='cuda:0') tensor(1.3770, device='cuda:0')
relations tensor([19.7940,  2.8912,  2.8807,  2.8808,  2.9027], device='cuda:0')
tensor([[0.0000, 0.6015, 0.6252, 0.6174, 0.6104],
        [0.6015, 0.0000, 0.1961, 0.1985, 0.1931],
        [0.6252, 0.1961, 0.0000, 0.1920, 0.2114],
        [0.6174, 0.1985, 0.1920, 0.0000, 0.2042],
        [0.6104, 0.1931, 0.2114, 0.2042, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([4.8655, 4.2275, 4.2648, 4.2174, 4.3364], device='cuda:0')
tensor([[0.0000, 0.6098, 0.6122, 0.6301, 0.6198],
        [0.6098, 0.0000, 0.8466, 0.8641, 0.8109],
        [0.6122, 0.8466, 0.0000, 0.8219, 0.8448],
        [0.6301, 0.8641, 0.8219, 0.0000, 0.8590],
        [0.6198, 0.8109, 0.8448, 0.8590, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 20 total loss 0.31891904348924527 0.00033464747480508423
epoch 21 total loss 0.2957135718820041 0.00031029755706401266
epoch 22 total loss 0.28836951030530145 0.00030259130147460803
epoch 23 total loss 0.26931571165897594 0.00028259780866629164
epoch 24 total loss 0.28207616604595387 0.0002959875824196788
aida-A micro F1: 0.9092996555683122
aida-B micro F1: 0.9168338907469342
msnbc micro F1: 0.9334353481254781
aquaint micro F1: 0.890909090909091
ace2004 micro F1: 0.9134808853118712
clueweb micro F1: 0.7774883219547252
wikipedia micro F1: 0.7728718290067303
att_mat_diag tensor(17.4071, device='cuda:0')
tok_score_mat_diag tensor(17.6365, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(23.1447, device='cuda:0') tensor(1.4158, device='cuda:0')
relations tensor([20.0223,  3.1806,  3.1700,  3.1679,  3.1917], device='cuda:0')
tensor([[0.0000, 0.6211, 0.6449, 0.6389, 0.6311],
        [0.6211, 0.0000, 0.1918, 0.1942, 0.1881],
        [0.6449, 0.1918, 0.0000, 0.1870, 0.2063],
        [0.6389, 0.1942, 0.1870, 0.0000, 0.1990],
        [0.6311, 0.1881, 0.2063, 0.1990, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([5.6777, 4.9380, 4.9527, 4.8983, 5.0221], device='cuda:0')
tensor([[0.0000, 0.5548, 0.5589, 0.5759, 0.5683],
        [0.5548, 0.0000, 0.7807, 0.7979, 0.7522],
        [0.5589, 0.7807, 0.0000, 0.7600, 0.7807],
        [0.5759, 0.7979, 0.7600, 0.0000, 0.7974],
        [0.5683, 0.7522, 0.7807, 0.7974, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 25 total loss 0.266419883806293 0.0002795591645396569
epoch 26 total loss 0.2692057850125593 0.00028248246066375586
epoch 27 total loss 0.2629373315054977 0.0002759048599218234
epoch 28 total loss 0.24995088230576812 0.0002622779457563149
epoch 29 total loss 0.25862192960050834 0.00027137663127020813
aida-A micro F1: 0.9078384302264898
aida-B micro F1: 0.9163879598662207
msnbc micro F1: 0.9349655700076511
aquaint micro F1: 0.8881118881118881
ace2004 micro F1: 0.9134808853118712
clueweb micro F1: 0.7797340998922027
wikipedia micro F1: 0.7699134679387619
att_mat_diag tensor(17.3870, device='cuda:0')
tok_score_mat_diag tensor(17.5514, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(25.1282, device='cuda:0') tensor(1.4251, device='cuda:0')
relations tensor([20.2073,  3.4106,  3.4002,  3.3974,  3.4225], device='cuda:0')
tensor([[0.0000, 0.6353, 0.6594, 0.6553, 0.6463],
        [0.6353, 0.0000, 0.1915, 0.1939, 0.1870],
        [0.6594, 0.1915, 0.0000, 0.1859, 0.2054],
        [0.6553, 0.1939, 0.1859, 0.0000, 0.1977],
        [0.6463, 0.1870, 0.2054, 0.1977, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([6.5094, 5.6468, 5.6456, 5.5770, 5.7157], device='cuda:0')
tensor([[0.0000, 0.5167, 0.5231, 0.5395, 0.5331],
        [0.5167, 0.0000, 0.7342, 0.7503, 0.7086],
        [0.5231, 0.7342, 0.0000, 0.7168, 0.7342],
        [0.5395, 0.7503, 0.7168, 0.0000, 0.7522],
        [0.5331, 0.7086, 0.7342, 0.7522, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 30 total loss 0.25714958270083343 0.0002698316712495629
epoch 31 total loss 0.2387484339888033 0.00025052301572802023
epoch 32 total loss 0.2360899419334146 0.00024773341231208246
epoch 33 total loss 0.22271101469794985 0.00023369466390131148
epoch 34 total loss 0.23163089240892987 0.0002430544516358131
aida-A micro F1: 0.9063772048846676
aida-B micro F1: 0.9259754738015608
msnbc micro F1: 0.9349655700076511
aquaint micro F1: 0.890909090909091
ace2004 micro F1: 0.9134808853118712
clueweb micro F1: 0.771200143729788
wikipedia micro F1: 0.7838177649582132
att_mat_diag tensor(17.3612, device='cuda:0')
tok_score_mat_diag tensor(17.4521, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(26.9989, device='cuda:0') tensor(1.4612, device='cuda:0')
relations tensor([20.3840,  3.6171,  3.6064,  3.6028,  3.6306], device='cuda:0')
tensor([[0.0000, 0.6456, 0.6699, 0.6674, 0.6575],
        [0.6456, 0.0000, 0.1926, 0.1952, 0.1873],
        [0.6699, 0.1926, 0.0000, 0.1867, 0.2061],
        [0.6674, 0.1952, 0.1867, 0.0000, 0.1979],
        [0.6575, 0.1873, 0.2061, 0.1979, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([7.3494, 6.3607, 6.3481, 6.2676, 6.4175], device='cuda:0')
tensor([[0.0000, 0.4846, 0.4922, 0.5090, 0.5040],
        [0.4846, 0.0000, 0.6924, 0.7074, 0.6700],
        [0.4922, 0.6924, 0.0000, 0.6777, 0.6917],
        [0.5090, 0.7074, 0.6777, 0.0000, 0.7109],
        [0.5040, 0.6700, 0.6917, 0.7109, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 35 total loss 0.22364751150644224 0.00023467734680634024
epoch 36 total loss 0.21991831976311005 0.0002307642389959182
epoch 37 total loss 0.22106255233410366 0.00023196490276401223
epoch 38 total loss 0.20869399070829786 0.00021898634911678684
epoch 39 total loss 0.2095531941732247 0.00021988792672951175
aida-A micro F1: 0.9170232752322306
aida-B micro F1: 0.9297658862876255
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.890909090909091
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7807222421846928
wikipedia micro F1: 0.7784927150358701
change learning rate to 1e-05
save model to 
att_mat_diag tensor(17.3497, device='cuda:0')
tok_score_mat_diag tensor(17.3682, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(28.6869, device='cuda:0') tensor(1.4741, device='cuda:0')
relations tensor([20.5587,  3.8177,  3.8068,  3.8001,  3.8320], device='cuda:0')
tensor([[0.0000, 0.6543, 0.6791, 0.6777, 0.6673],
        [0.6543, 0.0000, 0.1936, 0.1965, 0.1877],
        [0.6791, 0.1936, 0.0000, 0.1876, 0.2071],
        [0.6777, 0.1965, 0.1876, 0.0000, 0.1984],
        [0.6673, 0.1877, 0.2071, 0.1984, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.1606, 7.0701, 7.0397, 6.9512, 7.1201], device='cuda:0')
tensor([[0.0000, 0.4577, 0.4665, 0.4834, 0.4784],
        [0.4577, 0.0000, 0.6563, 0.6701, 0.6365],
        [0.4665, 0.6563, 0.0000, 0.6437, 0.6547],
        [0.4834, 0.6701, 0.6437, 0.0000, 0.6755],
        [0.4784, 0.6365, 0.6547, 0.6755, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 40 total loss 0.18545286745541034 0.0001945990214642291
epoch 41 total loss 0.18610839833144155 0.00019528688177485997
aida-A micro F1: 0.9163970358000209
aida-B micro F1: 0.9326644370122631
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8797202797202797
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.775691699604743
wikipedia micro F1: 0.7792323053028622
att_mat_diag tensor(17.3486, device='cuda:0')
tok_score_mat_diag tensor(17.3637, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(28.7432, device='cuda:0') tensor(1.4728, device='cuda:0')
relations tensor([20.5597,  3.8201,  3.8092,  3.8025,  3.8344], device='cuda:0')
tensor([[0.0000, 0.6553, 0.6802, 0.6789, 0.6684],
        [0.6553, 0.0000, 0.1940, 0.1968, 0.1880],
        [0.6802, 0.1940, 0.0000, 0.1879, 0.2074],
        [0.6789, 0.1968, 0.1879, 0.0000, 0.1987],
        [0.6684, 0.1880, 0.2074, 0.1987, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.1921, 7.0980, 7.0668, 6.9783, 7.1476], device='cuda:0')
tensor([[0.0000, 0.4568, 0.4656, 0.4825, 0.4775],
        [0.4568, 0.0000, 0.6550, 0.6688, 0.6353],
        [0.4656, 0.6550, 0.0000, 0.6424, 0.6534],
        [0.4825, 0.6688, 0.6424, 0.0000, 0.6743],
        [0.4775, 0.6353, 0.6534, 0.6743, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 42 total loss 0.1847948948246767 0.00019390859897657576
epoch 43 total loss 0.18339969555268 0.00019244459134593912
aida-A micro F1: 0.9124308527293603
aida-B micro F1: 0.9340022296544036
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8741258741258742
ace2004 micro F1: 0.89738430583501
clueweb micro F1: 0.771200143729788
wikipedia micro F1: 0.782338584424229
att_mat_diag tensor(17.3475, device='cuda:0')
tok_score_mat_diag tensor(17.3584, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(28.8029, device='cuda:0') tensor(1.4735, device='cuda:0')
relations tensor([20.5616,  3.8235,  3.8126,  3.8058,  3.8378], device='cuda:0')
tensor([[0.0000, 0.6564, 0.6813, 0.6801, 0.6695],
        [0.6564, 0.0000, 0.1942, 0.1972, 0.1883],
        [0.6813, 0.1942, 0.0000, 0.1882, 0.2077],
        [0.6801, 0.1972, 0.1882, 0.0000, 0.1990],
        [0.6695, 0.1883, 0.2077, 0.1990, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.2241, 7.1287, 7.0968, 7.0086, 7.1782], device='cuda:0')
tensor([[0.0000, 0.4556, 0.4644, 0.4813, 0.4762],
        [0.4556, 0.0000, 0.6535, 0.6672, 0.6339],
        [0.4644, 0.6535, 0.0000, 0.6410, 0.6518],
        [0.4813, 0.6672, 0.6410, 0.0000, 0.6728],
        [0.4762, 0.6339, 0.6518, 0.6728, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 44 total loss 0.18486031359321942 0.00019397724406423864
epoch 45 total loss 0.18262229309465283 0.00019162884899753707
aida-A micro F1: 0.9172320217096337
aida-B micro F1: 0.9322185061315497
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7770391663672296
wikipedia micro F1: 0.7790843872494637
save model to 
att_mat_diag tensor(17.3467, device='cuda:0')
tok_score_mat_diag tensor(17.3531, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(28.8612, device='cuda:0') tensor(1.4727, device='cuda:0')
relations tensor([20.5636,  3.8269,  3.8159,  3.8091,  3.8412], device='cuda:0')
tensor([[0.0000, 0.6574, 0.6824, 0.6813, 0.6706],
        [0.6574, 0.0000, 0.1946, 0.1975, 0.1885],
        [0.6824, 0.1946, 0.0000, 0.1885, 0.2081],
        [0.6813, 0.1975, 0.1885, 0.0000, 0.1993],
        [0.6706, 0.1885, 0.2081, 0.1993, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.2555, 7.1581, 7.1255, 7.0377, 7.2077], device='cuda:0')
tensor([[0.0000, 0.4546, 0.4633, 0.4801, 0.4751],
        [0.4546, 0.0000, 0.6521, 0.6658, 0.6327],
        [0.4633, 0.6521, 0.0000, 0.6397, 0.6505],
        [0.4801, 0.6658, 0.6397, 0.0000, 0.6714],
        [0.4751, 0.6327, 0.6505, 0.6714, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 46 total loss 0.1822687744759719 0.00019125789556765152
epoch 47 total loss 0.18182454055124708 0.00019079175293939881
aida-A micro F1: 0.91764951466444
aida-B micro F1: 0.9317725752508361
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8895104895104895
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.778296802012217
wikipedia micro F1: 0.7793802233562607
save model to 
att_mat_diag tensor(17.3460, device='cuda:0')
tok_score_mat_diag tensor(17.3482, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(28.9237, device='cuda:0') tensor(1.4727, device='cuda:0')
relations tensor([20.5660,  3.8306,  3.8196,  3.8127,  3.8449], device='cuda:0')
tensor([[0.0000, 0.6584, 0.6835, 0.6823, 0.6716],
        [0.6584, 0.0000, 0.1948, 0.1978, 0.1888],
        [0.6835, 0.1948, 0.0000, 0.1888, 0.2084],
        [0.6823, 0.1978, 0.1888, 0.0000, 0.1996],
        [0.6716, 0.1888, 0.2084, 0.1996, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.2877, 7.1889, 7.1562, 7.0680, 7.2386], device='cuda:0')
tensor([[0.0000, 0.4534, 0.4621, 0.4789, 0.4739],
        [0.4534, 0.0000, 0.6506, 0.6642, 0.6312],
        [0.4621, 0.6506, 0.0000, 0.6382, 0.6489],
        [0.4789, 0.6642, 0.6382, 0.0000, 0.6700],
        [0.4739, 0.6312, 0.6489, 0.6700, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 48 total loss 0.18093020642527335 0.00018985331209367612
epoch 49 total loss 0.18106750950869355 0.00018999738668278442
aida-A micro F1: 0.9178582611418432
aida-B micro F1: 0.9308807134894092
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8881118881118881
ace2004 micro F1: 0.9094567404426559
clueweb micro F1: 0.7797340998922027
wikipedia micro F1: 0.778788551142667
save model to 
att_mat_diag tensor(17.3445, device='cuda:0')
tok_score_mat_diag tensor(17.3434, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(28.9853, device='cuda:0') tensor(1.4717, device='cuda:0')
relations tensor([20.5682,  3.8339,  3.8230,  3.8160,  3.8483], device='cuda:0')
tensor([[0.0000, 0.6594, 0.6845, 0.6834, 0.6726],
        [0.6594, 0.0000, 0.1951, 0.1981, 0.1891],
        [0.6845, 0.1951, 0.0000, 0.1891, 0.2087],
        [0.6834, 0.1981, 0.1891, 0.0000, 0.1999],
        [0.6726, 0.1891, 0.2087, 0.1999, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.3208, 7.2204, 7.1873, 7.0993, 7.2698], device='cuda:0')
tensor([[0.0000, 0.4522, 0.4609, 0.4776, 0.4726],
        [0.4522, 0.0000, 0.6490, 0.6626, 0.6298],
        [0.4609, 0.6490, 0.0000, 0.6367, 0.6473],
        [0.4776, 0.6626, 0.6367, 0.0000, 0.6684],
        [0.4726, 0.6298, 0.6473, 0.6684, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 50 total loss 0.17972368871750177 0.00018858729141395779
epoch 51 total loss 0.1791798306524015 0.00018801661138761962
aida-A micro F1: 0.9161882893226176
aida-B micro F1: 0.9253065774804905
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8895104895104895
ace2004 micro F1: 0.9094567404426559
clueweb micro F1: 0.7801832554796982
wikipedia micro F1: 0.7747947637009096
att_mat_diag tensor(17.3437, device='cuda:0')
tok_score_mat_diag tensor(17.3389, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.0392, device='cuda:0') tensor(1.4731, device='cuda:0')
relations tensor([20.5703,  3.8372,  3.8262,  3.8192,  3.8516], device='cuda:0')
tensor([[0.0000, 0.6603, 0.6855, 0.6845, 0.6737],
        [0.6603, 0.0000, 0.1954, 0.1984, 0.1893],
        [0.6855, 0.1954, 0.0000, 0.1894, 0.2090],
        [0.6845, 0.1984, 0.1894, 0.0000, 0.2001],
        [0.6737, 0.1893, 0.2090, 0.2001, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.3492, 7.2495, 7.2164, 7.1286, 7.2992], device='cuda:0')
tensor([[0.0000, 0.4510, 0.4597, 0.4764, 0.4714],
        [0.4510, 0.0000, 0.6475, 0.6611, 0.6284],
        [0.4597, 0.6475, 0.0000, 0.6353, 0.6458],
        [0.4764, 0.6611, 0.6353, 0.0000, 0.6670],
        [0.4714, 0.6284, 0.6458, 0.6670, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 52 total loss 0.1796890095321828 0.0001885509019225423
epoch 53 total loss 0.178494394433244 0.00018729737086384469
aida-A micro F1: 0.9166057822774241
aida-B micro F1: 0.9335562987736901
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8783216783216785
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7746137261947538
wikipedia micro F1: 0.7807114858368464
att_mat_diag tensor(17.3427, device='cuda:0')
tok_score_mat_diag tensor(17.3347, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.0983, device='cuda:0') tensor(1.4733, device='cuda:0')
relations tensor([20.5728,  3.8408,  3.8298,  3.8227,  3.8552], device='cuda:0')
tensor([[0.0000, 0.6612, 0.6864, 0.6854, 0.6746],
        [0.6612, 0.0000, 0.1957, 0.1987, 0.1896],
        [0.6864, 0.1957, 0.0000, 0.1896, 0.2093],
        [0.6854, 0.1987, 0.1896, 0.0000, 0.2004],
        [0.6746, 0.1896, 0.2093, 0.2004, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.3787, 7.2784, 7.2452, 7.1574, 7.3281], device='cuda:0')
tensor([[0.0000, 0.4499, 0.4585, 0.4752, 0.4702],
        [0.4499, 0.0000, 0.6460, 0.6596, 0.6272],
        [0.4585, 0.6460, 0.0000, 0.6340, 0.6444],
        [0.4752, 0.6596, 0.6340, 0.0000, 0.6656],
        [0.4702, 0.6272, 0.6444, 0.6656, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 54 total loss 0.17899500766105803 0.00018782267330646172
epoch 55 total loss 0.17808471421750482 0.00018686748606243947
aida-A micro F1: 0.9184845005740527
aida-B micro F1: 0.9324414715719064
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7782069708947179
wikipedia micro F1: 0.7781968789290732
save model to 
att_mat_diag tensor(17.3418, device='cuda:0')
tok_score_mat_diag tensor(17.3303, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.1554, device='cuda:0') tensor(1.4727, device='cuda:0')
relations tensor([20.5745,  3.8436,  3.8327,  3.8255,  3.8580], device='cuda:0')
tensor([[0.0000, 0.6622, 0.6875, 0.6865, 0.6756],
        [0.6622, 0.0000, 0.1960, 0.1991, 0.1899],
        [0.6875, 0.1960, 0.0000, 0.1900, 0.2096],
        [0.6865, 0.1991, 0.1900, 0.0000, 0.2007],
        [0.6756, 0.1899, 0.2096, 0.2007, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.4089, 7.3079, 7.2749, 7.1872, 7.3577], device='cuda:0')
tensor([[0.0000, 0.4488, 0.4574, 0.4741, 0.4691],
        [0.4488, 0.0000, 0.6446, 0.6581, 0.6259],
        [0.4574, 0.6446, 0.0000, 0.6326, 0.6429],
        [0.4741, 0.6581, 0.6326, 0.0000, 0.6642],
        [0.4691, 0.6259, 0.6429, 0.6642, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 56 total loss 0.17677832400147508 0.0001854966673677598
epoch 57 total loss 0.17638924630659858 0.00018508840116117375
aida-A micro F1: 0.918693247051456
aida-B micro F1: 0.9317725752508361
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7791052820697091
wikipedia micro F1: 0.7774572886620812
save model to 
att_mat_diag tensor(17.3411, device='cuda:0')
tok_score_mat_diag tensor(17.3264, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.2150, device='cuda:0') tensor(1.4732, device='cuda:0')
relations tensor([20.5770,  3.8471,  3.8361,  3.8288,  3.8614], device='cuda:0')
tensor([[0.0000, 0.6630, 0.6883, 0.6875, 0.6765],
        [0.6630, 0.0000, 0.1963, 0.1994, 0.1901],
        [0.6883, 0.1963, 0.0000, 0.1902, 0.2099],
        [0.6875, 0.1994, 0.1902, 0.0000, 0.2010],
        [0.6765, 0.1901, 0.2099, 0.2010, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.4411, 7.3387, 7.3053, 7.2173, 7.3884], device='cuda:0')
tensor([[0.0000, 0.4477, 0.4562, 0.4730, 0.4679],
        [0.4477, 0.0000, 0.6431, 0.6566, 0.6245],
        [0.4562, 0.6431, 0.0000, 0.6312, 0.6414],
        [0.4730, 0.6566, 0.6312, 0.0000, 0.6627],
        [0.4679, 0.6245, 0.6414, 0.6627, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 58 total loss 0.1761711362087226 0.00018485953432184952
epoch 59 total loss 0.17596710672529525 0.00018464544252391946
aida-A micro F1: 0.9174407681870368
aida-B micro F1: 0.9335562987736901
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8811188811188811
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7755120373697448
wikipedia micro F1: 0.7813031580504401
att_mat_diag tensor(17.3406, device='cuda:0')
tok_score_mat_diag tensor(17.3218, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.2751, device='cuda:0') tensor(1.4723, device='cuda:0')
relations tensor([20.5798,  3.8511,  3.8400,  3.8327,  3.8654], device='cuda:0')
tensor([[0.0000, 0.6639, 0.6892, 0.6884, 0.6774],
        [0.6639, 0.0000, 0.1965, 0.1996, 0.1903],
        [0.6892, 0.1965, 0.0000, 0.1905, 0.2102],
        [0.6884, 0.1996, 0.1905, 0.0000, 0.2012],
        [0.6774, 0.1903, 0.2102, 0.2012, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.4732, 7.3688, 7.3345, 7.2467, 7.4180], device='cuda:0')
tensor([[0.0000, 0.4468, 0.4553, 0.4720, 0.4669],
        [0.4468, 0.0000, 0.6417, 0.6552, 0.6232],
        [0.4553, 0.6417, 0.0000, 0.6299, 0.6400],
        [0.4720, 0.6552, 0.6299, 0.0000, 0.6614],
        [0.4669, 0.6232, 0.6400, 0.6614, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 60 total loss 0.17638020860812276 0.0001850789177419966
epoch 61 total loss 0.17498955248072434 0.00018361967731450612
aida-A micro F1: 0.918693247051456
aida-B micro F1: 0.9337792642140468
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8895104895104895
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7783866331297161
wikipedia micro F1: 0.7790843872494637
save model to 
att_mat_diag tensor(17.3398, device='cuda:0')
tok_score_mat_diag tensor(17.3175, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.3325, device='cuda:0') tensor(1.4726, device='cuda:0')
relations tensor([20.5825,  3.8549,  3.8438,  3.8364,  3.8692], device='cuda:0')
tensor([[0.0000, 0.6647, 0.6902, 0.6894, 0.6784],
        [0.6647, 0.0000, 0.1968, 0.1999, 0.1906],
        [0.6902, 0.1968, 0.0000, 0.1907, 0.2105],
        [0.6894, 0.1999, 0.1907, 0.0000, 0.2015],
        [0.6784, 0.1906, 0.2105, 0.2015, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.5050, 7.3990, 7.3642, 7.2765, 7.4483], device='cuda:0')
tensor([[0.0000, 0.4457, 0.4542, 0.4710, 0.4658],
        [0.4457, 0.0000, 0.6403, 0.6537, 0.6219],
        [0.4542, 0.6403, 0.0000, 0.6286, 0.6386],
        [0.4710, 0.6537, 0.6286, 0.0000, 0.6600],
        [0.4658, 0.6219, 0.6386, 0.6600, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 62 total loss 0.17477931506863342 0.00018339907142563843
epoch 63 total loss 0.1741760135744812 0.0001827660163425826
aida-A micro F1: 0.9180670076192464
aida-B micro F1: 0.9335562987736901
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7779374775422206
wikipedia micro F1: 0.7795281414096591
att_mat_diag tensor(17.3388, device='cuda:0')
tok_score_mat_diag tensor(17.3131, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.3880, device='cuda:0') tensor(1.4727, device='cuda:0')
relations tensor([20.5854,  3.8591,  3.8481,  3.8406,  3.8735], device='cuda:0')
tensor([[0.0000, 0.6656, 0.6911, 0.6904, 0.6793],
        [0.6656, 0.0000, 0.1970, 0.2002, 0.1908],
        [0.6911, 0.1970, 0.0000, 0.1910, 0.2107],
        [0.6904, 0.2002, 0.1910, 0.0000, 0.2017],
        [0.6793, 0.1908, 0.2107, 0.2017, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.5358, 7.4280, 7.3930, 7.3053, 7.4773], device='cuda:0')
tensor([[0.0000, 0.4448, 0.4532, 0.4699, 0.4648],
        [0.4448, 0.0000, 0.6390, 0.6524, 0.6207],
        [0.4532, 0.6390, 0.0000, 0.6274, 0.6373],
        [0.4699, 0.6524, 0.6274, 0.0000, 0.6587],
        [0.4648, 0.6207, 0.6373, 0.6587, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 64 total loss 0.17340233348875245 0.00018195417994622503
epoch 65 total loss 0.1729419213785377 0.00018147106125764712
aida-A micro F1: 0.9189019935288592
aida-B micro F1: 0.9331103678929766
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8825174825174825
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.776500179662235
wikipedia micro F1: 0.7793802233562607
save model to 
att_mat_diag tensor(17.3377, device='cuda:0')
tok_score_mat_diag tensor(17.3088, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.4459, device='cuda:0') tensor(1.4741, device='cuda:0')
relations tensor([20.5883,  3.8628,  3.8518,  3.8442,  3.8771], device='cuda:0')
tensor([[0.0000, 0.6664, 0.6919, 0.6912, 0.6801],
        [0.6664, 0.0000, 0.1973, 0.2005, 0.1911],
        [0.6919, 0.1973, 0.0000, 0.1912, 0.2110],
        [0.6912, 0.2005, 0.1912, 0.0000, 0.2020],
        [0.6801, 0.1911, 0.2110, 0.2020, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.5685, 7.4590, 7.4236, 7.3359, 7.5076], device='cuda:0')
tensor([[0.0000, 0.4437, 0.4521, 0.4688, 0.4637],
        [0.4437, 0.0000, 0.6376, 0.6510, 0.6194],
        [0.4521, 0.6376, 0.0000, 0.6261, 0.6359],
        [0.4688, 0.6510, 0.6261, 0.0000, 0.6574],
        [0.4637, 0.6194, 0.6359, 0.6574, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 66 total loss 0.171908138768174 0.00018038629461508292
epoch 67 total loss 0.17293805672329654 0.00018146700600555775
aida-A micro F1: 0.9195282329610688
aida-B micro F1: 0.9322185061315497
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7789256198347109
wikipedia micro F1: 0.7781968789290732
save model to 
att_mat_diag tensor(17.3374, device='cuda:0')
tok_score_mat_diag tensor(17.3039, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.5038, device='cuda:0') tensor(1.4758, device='cuda:0')
relations tensor([20.5917,  3.8674,  3.8563,  3.8487,  3.8817], device='cuda:0')
tensor([[0.0000, 0.6672, 0.6927, 0.6921, 0.6810],
        [0.6672, 0.0000, 0.1976, 0.2007, 0.1913],
        [0.6927, 0.1976, 0.0000, 0.1915, 0.2113],
        [0.6921, 0.2007, 0.1915, 0.0000, 0.2022],
        [0.6810, 0.1913, 0.2113, 0.2022, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.6010, 7.4900, 7.4537, 7.3665, 7.5383], device='cuda:0')
tensor([[0.0000, 0.4427, 0.4510, 0.4678, 0.4626],
        [0.4427, 0.0000, 0.6362, 0.6496, 0.6181],
        [0.4510, 0.6362, 0.0000, 0.6247, 0.6345],
        [0.4678, 0.6496, 0.6247, 0.0000, 0.6560],
        [0.4626, 0.6181, 0.6345, 0.6560, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 68 total loss 0.17214979564982968 0.00018063986951713504
epoch 69 total loss 0.17223872030888288 0.00018073317975748465
aida-A micro F1: 0.9189019935288592
aida-B micro F1: 0.9328874024526198
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7780273086597198
wikipedia micro F1: 0.7790843872494637
att_mat_diag tensor(17.3371, device='cuda:0')
tok_score_mat_diag tensor(17.2999, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.5585, device='cuda:0') tensor(1.4752, device='cuda:0')
relations tensor([20.5940,  3.8708,  3.8597,  3.8520,  3.8850], device='cuda:0')
tensor([[0.0000, 0.6680, 0.6936, 0.6930, 0.6818],
        [0.6680, 0.0000, 0.1979, 0.2011, 0.1915],
        [0.6936, 0.1979, 0.0000, 0.1918, 0.2116],
        [0.6930, 0.2011, 0.1918, 0.0000, 0.2025],
        [0.6818, 0.1915, 0.2116, 0.2025, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.6317, 7.5189, 7.4817, 7.3945, 7.5665], device='cuda:0')
tensor([[0.0000, 0.4419, 0.4502, 0.4669, 0.4617],
        [0.4419, 0.0000, 0.6350, 0.6483, 0.6170],
        [0.4502, 0.6350, 0.0000, 0.6236, 0.6333],
        [0.4669, 0.6483, 0.6236, 0.0000, 0.6549],
        [0.4617, 0.6170, 0.6333, 0.6549, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 70 total loss 0.17125307285527924 0.0001796989221986141
epoch 71 total loss 0.17073178634046826 0.00017915192690500341
aida-A micro F1: 0.9189019935288592
aida-B micro F1: 0.9328874024526198
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8811188811188811
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7759611929572403
wikipedia micro F1: 0.7799718955698544
att_mat_diag tensor(17.3366, device='cuda:0')
tok_score_mat_diag tensor(17.2952, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.6150, device='cuda:0') tensor(1.4739, device='cuda:0')
relations tensor([20.5975,  3.8752,  3.8641,  3.8563,  3.8893], device='cuda:0')
tensor([[0.0000, 0.6687, 0.6944, 0.6939, 0.6826],
        [0.6687, 0.0000, 0.1981, 0.2013, 0.1918],
        [0.6944, 0.1981, 0.0000, 0.1920, 0.2119],
        [0.6939, 0.2013, 0.1920, 0.0000, 0.2027],
        [0.6826, 0.1918, 0.2119, 0.2027, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.6629, 7.5471, 7.5096, 7.4222, 7.5943], device='cuda:0')
tensor([[0.0000, 0.4410, 0.4492, 0.4660, 0.4608],
        [0.4410, 0.0000, 0.6338, 0.6471, 0.6159],
        [0.4492, 0.6338, 0.0000, 0.6224, 0.6320],
        [0.4660, 0.6471, 0.6224, 0.0000, 0.6537],
        [0.4608, 0.6159, 0.6320, 0.6537, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 72 total loss 0.17118930702844182 0.0001796320115723419
epoch 73 total loss 0.1704183988322825 0.00017882308376944648
aida-A micro F1: 0.9191107400062625
aida-B micro F1: 0.9299888517279822
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8881118881118881
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7802730865971973
wikipedia micro F1: 0.7771614525552843
att_mat_diag tensor(17.3365, device='cuda:0')
tok_score_mat_diag tensor(17.2907, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.6734, device='cuda:0') tensor(1.4732, device='cuda:0')
relations tensor([20.6008,  3.8798,  3.8687,  3.8608,  3.8939], device='cuda:0')
tensor([[0.0000, 0.6695, 0.6952, 0.6948, 0.6835],
        [0.6695, 0.0000, 0.1984, 0.2016, 0.1920],
        [0.6952, 0.1984, 0.0000, 0.1922, 0.2121],
        [0.6948, 0.2016, 0.1922, 0.0000, 0.2029],
        [0.6835, 0.1920, 0.2121, 0.2029, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.6952, 7.5767, 7.5386, 7.4510, 7.6237], device='cuda:0')
tensor([[0.0000, 0.4401, 0.4483, 0.4651, 0.4599],
        [0.4401, 0.0000, 0.6325, 0.6458, 0.6147],
        [0.4483, 0.6325, 0.0000, 0.6212, 0.6307],
        [0.4651, 0.6458, 0.6212, 0.0000, 0.6525],
        [0.4599, 0.6147, 0.6307, 0.6525, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 74 total loss 0.16845746325543587 0.00017676543888293374
epoch 75 total loss 0.16936526335734925 0.00017771800981883446
aida-A micro F1: 0.9203632188706815
aida-B micro F1: 0.9322185061315497
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8867132867132868
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7796442687747035
wikipedia micro F1: 0.777753124768878
save model to 
att_mat_diag tensor(17.3356, device='cuda:0')
tok_score_mat_diag tensor(17.2867, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.7312, device='cuda:0') tensor(1.4737, device='cuda:0')
relations tensor([20.6047,  3.8843,  3.8732,  3.8652,  3.8983], device='cuda:0')
tensor([[0.0000, 0.6700, 0.6958, 0.6954, 0.6840],
        [0.6700, 0.0000, 0.1986, 0.2018, 0.1922],
        [0.6958, 0.1986, 0.0000, 0.1925, 0.2123],
        [0.6954, 0.2018, 0.1925, 0.0000, 0.2032],
        [0.6840, 0.1922, 0.2123, 0.2032, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.7281, 7.6067, 7.5679, 7.4805, 7.6530], device='cuda:0')
tensor([[0.0000, 0.4392, 0.4475, 0.4643, 0.4591],
        [0.4392, 0.0000, 0.6312, 0.6444, 0.6135],
        [0.4475, 0.6312, 0.0000, 0.6199, 0.6294],
        [0.4643, 0.6444, 0.6199, 0.0000, 0.6512],
        [0.4591, 0.6135, 0.6294, 0.6512, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 76 total loss 0.16916067367486676 0.000177503330193984
epoch 77 total loss 0.16788087707766408 0.00017616041666071783
aida-A micro F1: 0.9193194864836656
aida-B micro F1: 0.9335562987736901
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8867132867132868
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7783866331297161
wikipedia micro F1: 0.7796760594630574
att_mat_diag tensor(17.3350, device='cuda:0')
tok_score_mat_diag tensor(17.2825, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.7862, device='cuda:0') tensor(1.4742, device='cuda:0')
relations tensor([20.6080,  3.8886,  3.8775,  3.8694,  3.9026], device='cuda:0')
tensor([[0.0000, 0.6707, 0.6965, 0.6962, 0.6848],
        [0.6707, 0.0000, 0.1988, 0.2021, 0.1924],
        [0.6965, 0.1988, 0.0000, 0.1927, 0.2126],
        [0.6962, 0.2021, 0.1927, 0.0000, 0.2034],
        [0.6848, 0.1924, 0.2126, 0.2034, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.7594, 7.6357, 7.5960, 7.5089, 7.6814], device='cuda:0')
tensor([[0.0000, 0.4383, 0.4466, 0.4634, 0.4582],
        [0.4383, 0.0000, 0.6300, 0.6432, 0.6123],
        [0.4466, 0.6300, 0.0000, 0.6188, 0.6282],
        [0.4634, 0.6432, 0.6188, 0.0000, 0.6500],
        [0.4582, 0.6123, 0.6282, 0.6500, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 78 total loss 0.16816585645375426 0.00017645945063353018
epoch 79 total loss 0.1678733965511583 0.00017615256721002968
aida-A micro F1: 0.9203632188706815
aida-B micro F1: 0.9324414715719064
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8867132867132868
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7793747754222062
wikipedia micro F1: 0.7779010428222765
save model to 
att_mat_diag tensor(17.3342, device='cuda:0')
tok_score_mat_diag tensor(17.2784, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.8401, device='cuda:0') tensor(1.4739, device='cuda:0')
relations tensor([20.6115,  3.8931,  3.8820,  3.8739,  3.9071], device='cuda:0')
tensor([[0.0000, 0.6714, 0.6973, 0.6970, 0.6855],
        [0.6714, 0.0000, 0.1991, 0.2024, 0.1926],
        [0.6973, 0.1991, 0.0000, 0.1930, 0.2129],
        [0.6970, 0.2024, 0.1930, 0.0000, 0.2036],
        [0.6855, 0.1926, 0.2129, 0.2036, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.7900, 7.6642, 7.6237, 7.5366, 7.7093], device='cuda:0')
tensor([[0.0000, 0.4374, 0.4458, 0.4626, 0.4574],
        [0.4374, 0.0000, 0.6288, 0.6420, 0.6112],
        [0.4458, 0.6288, 0.0000, 0.6177, 0.6270],
        [0.4626, 0.6420, 0.6177, 0.0000, 0.6488],
        [0.4574, 0.6112, 0.6270, 0.6488, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 80 total loss 0.1671961483189648 0.0001754419184878959
epoch 81 total loss 0.16665638029400043 0.0001748755302140613
aida-A micro F1: 0.9199457259158752
aida-B micro F1: 0.9335562987736901
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8853146853146854
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7778476464247215
wikipedia micro F1: 0.7784927150358701
att_mat_diag tensor(17.3342, device='cuda:0')
tok_score_mat_diag tensor(17.2746, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.8848, device='cuda:0') tensor(1.4750, device='cuda:0')
relations tensor([20.6146,  3.8971,  3.8859,  3.8778,  3.9111], device='cuda:0')
tensor([[0.0000, 0.6721, 0.6980, 0.6978, 0.6863],
        [0.6721, 0.0000, 0.1993, 0.2026, 0.1928],
        [0.6980, 0.1993, 0.0000, 0.1932, 0.2131],
        [0.6978, 0.2026, 0.1932, 0.0000, 0.2038],
        [0.6863, 0.1928, 0.2131, 0.2038, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.8140, 7.6860, 7.6451, 7.5574, 7.7302], device='cuda:0')
tensor([[0.0000, 0.4368, 0.4451, 0.4620, 0.4567],
        [0.4368, 0.0000, 0.6279, 0.6411, 0.6104],
        [0.4451, 0.6279, 0.0000, 0.6168, 0.6261],
        [0.4620, 0.6411, 0.6168, 0.0000, 0.6480],
        [0.4567, 0.6104, 0.6261, 0.6480, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 82 total loss 0.1664130145471745 0.0001746201621691233
epoch 83 total loss 0.1654786797170118 0.000173639747866749
aida-A micro F1: 0.918693247051456
aida-B micro F1: 0.9335562987736901
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8797202797202797
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.775691699604743
wikipedia micro F1: 0.7808594038902448
att_mat_diag tensor(17.3337, device='cuda:0')
tok_score_mat_diag tensor(17.2706, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.9328, device='cuda:0') tensor(1.4751, device='cuda:0')
relations tensor([20.6182,  3.9015,  3.8904,  3.8822,  3.9155], device='cuda:0')
tensor([[0.0000, 0.6727, 0.6987, 0.6985, 0.6869],
        [0.6727, 0.0000, 0.1995, 0.2029, 0.1930],
        [0.6987, 0.1995, 0.0000, 0.1934, 0.2133],
        [0.6985, 0.2029, 0.1934, 0.0000, 0.2040],
        [0.6869, 0.1930, 0.2133, 0.2040, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.8404, 7.7108, 7.6698, 7.5816, 7.7546], device='cuda:0')
tensor([[0.0000, 0.4361, 0.4444, 0.4614, 0.4560],
        [0.4361, 0.0000, 0.6267, 0.6400, 0.6094],
        [0.4444, 0.6267, 0.0000, 0.6158, 0.6250],
        [0.4614, 0.6400, 0.6158, 0.0000, 0.6469],
        [0.4560, 0.6094, 0.6250, 0.6469, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 84 total loss 0.16531322222454037 0.0001734661303510392
epoch 85 total loss 0.16514466484466084 0.00017328926006784977
aida-A micro F1: 0.9197369794384719
aida-B micro F1: 0.9331103678929766
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8797202797202797
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7768595041322314
wikipedia micro F1: 0.7790843872494637
att_mat_diag tensor(17.3328, device='cuda:0')
tok_score_mat_diag tensor(17.2662, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(29.9849, device='cuda:0') tensor(1.4755, device='cuda:0')
relations tensor([20.6220,  3.9062,  3.8950,  3.8868,  3.9202], device='cuda:0')
tensor([[0.0000, 0.6733, 0.6993, 0.6993, 0.6876],
        [0.6733, 0.0000, 0.1997, 0.2031, 0.1932],
        [0.6993, 0.1997, 0.0000, 0.1936, 0.2135],
        [0.6993, 0.2031, 0.1936, 0.0000, 0.2042],
        [0.6876, 0.1932, 0.2135, 0.2042, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.8709, 7.7393, 7.6980, 7.6094, 7.7827], device='cuda:0')
tensor([[0.0000, 0.4352, 0.4435, 0.4605, 0.4552],
        [0.4352, 0.0000, 0.6255, 0.6388, 0.6083],
        [0.4435, 0.6255, 0.0000, 0.6147, 0.6237],
        [0.4605, 0.6388, 0.6147, 0.0000, 0.6457],
        [0.4552, 0.6083, 0.6237, 0.6457, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 86 total loss 0.16412731045141982 0.00017222173184828943
epoch 87 total loss 0.16433839702318664 0.0001724432287756418
aida-A micro F1: 0.9193194864836656
aida-B micro F1: 0.9331103678929766
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8797202797202797
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7746137261947538
wikipedia micro F1: 0.7817469122106352
att_mat_diag tensor(17.3317, device='cuda:0')
tok_score_mat_diag tensor(17.2620, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.0402, device='cuda:0') tensor(1.4752, device='cuda:0')
relations tensor([20.6257,  3.9106,  3.8996,  3.8912,  3.9247], device='cuda:0')
tensor([[0.0000, 0.6739, 0.7000, 0.7000, 0.6883],
        [0.6739, 0.0000, 0.1999, 0.2034, 0.1934],
        [0.7000, 0.1999, 0.0000, 0.1938, 0.2137],
        [0.7000, 0.2034, 0.1938, 0.0000, 0.2044],
        [0.6883, 0.1934, 0.2137, 0.2044, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.9038, 7.7700, 7.7276, 7.6392, 7.8128], device='cuda:0')
tensor([[0.0000, 0.4343, 0.4426, 0.4597, 0.4543],
        [0.4343, 0.0000, 0.6242, 0.6375, 0.6071],
        [0.4426, 0.6242, 0.0000, 0.6135, 0.6224],
        [0.4597, 0.6375, 0.6135, 0.0000, 0.6445],
        [0.4543, 0.6071, 0.6224, 0.6445, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 88 total loss 0.16373999823917984 0.00017181531819431253
epoch 89 total loss 0.16330605523342 0.00017135997401198323
aida-A micro F1: 0.9195282329610688
aida-B micro F1: 0.9333333333333333
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8811188811188811
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7761408551922386
wikipedia micro F1: 0.7799718955698544
att_mat_diag tensor(17.3306, device='cuda:0')
tok_score_mat_diag tensor(17.2581, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.0940, device='cuda:0') tensor(1.4752, device='cuda:0')
relations tensor([20.6294,  3.9150,  3.9039,  3.8955,  3.9290], device='cuda:0')
tensor([[0.0000, 0.6745, 0.7006, 0.7006, 0.6889],
        [0.6745, 0.0000, 0.2002, 0.2036, 0.1936],
        [0.7006, 0.2002, 0.0000, 0.1940, 0.2139],
        [0.7006, 0.2036, 0.1940, 0.0000, 0.2046],
        [0.6889, 0.1936, 0.2139, 0.2046, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.9356, 7.7989, 7.7558, 7.6675, 7.8411], device='cuda:0')
tensor([[0.0000, 0.4335, 0.4418, 0.4589, 0.4535],
        [0.4335, 0.0000, 0.6231, 0.6363, 0.6060],
        [0.4418, 0.6231, 0.0000, 0.6124, 0.6212],
        [0.4589, 0.6363, 0.6124, 0.0000, 0.6434],
        [0.4535, 0.6060, 0.6212, 0.6434, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 90 total loss 0.16280966489063076 0.00017083910271839534
epoch 91 total loss 0.16230282572865917 0.00017030726729135276
aida-A micro F1: 0.9180670076192464
aida-B micro F1: 0.9337792642140468
msnbc micro F1: 0.9349655700076511
aquaint micro F1: 0.8685314685314686
ace2004 micro F1: 0.89738430583501
clueweb micro F1: 0.7714696370822852
wikipedia micro F1: 0.7826344205310259
att_mat_diag tensor(17.3297, device='cuda:0')
tok_score_mat_diag tensor(17.2538, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.1483, device='cuda:0') tensor(1.4753, device='cuda:0')
relations tensor([20.6334,  3.9200,  3.9089,  3.9005,  3.9340], device='cuda:0')
tensor([[0.0000, 0.6751, 0.7013, 0.7014, 0.6896],
        [0.6751, 0.0000, 0.2004, 0.2038, 0.1938],
        [0.7013, 0.2004, 0.0000, 0.1943, 0.2142],
        [0.7014, 0.2038, 0.1943, 0.0000, 0.2048],
        [0.6896, 0.1938, 0.2142, 0.2048, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.9674, 7.8277, 7.7841, 7.6959, 7.8693], device='cuda:0')
tensor([[0.0000, 0.4327, 0.4410, 0.4581, 0.4527],
        [0.4327, 0.0000, 0.6219, 0.6352, 0.6050],
        [0.4410, 0.6219, 0.0000, 0.6113, 0.6201],
        [0.4581, 0.6352, 0.6113, 0.0000, 0.6423],
        [0.4527, 0.6050, 0.6201, 0.6423, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 92 total loss 0.16243918313858785 0.00017045034956829786
epoch 93 total loss 0.16193026633300178 0.00016991633403253074
aida-A micro F1: 0.9214069512576976
aida-B micro F1: 0.9328874024526198
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8825174825174825
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7774883219547252
wikipedia micro F1: 0.777013534501886
save model to 
att_mat_diag tensor(17.3289, device='cuda:0')
tok_score_mat_diag tensor(17.2498, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.2002, device='cuda:0') tensor(1.4746, device='cuda:0')
relations tensor([20.6370,  3.9245,  3.9134,  3.9049,  3.9385], device='cuda:0')
tensor([[0.0000, 0.6757, 0.7019, 0.7020, 0.6902],
        [0.6757, 0.0000, 0.2006, 0.2041, 0.1940],
        [0.7019, 0.2006, 0.0000, 0.1945, 0.2144],
        [0.7020, 0.2041, 0.1945, 0.0000, 0.2050],
        [0.6902, 0.1940, 0.2144, 0.2050, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([8.9970, 7.8558, 7.8115, 7.7234, 7.8969], device='cuda:0')
tensor([[0.0000, 0.4319, 0.4402, 0.4574, 0.4520],
        [0.4319, 0.0000, 0.6208, 0.6340, 0.6040],
        [0.4402, 0.6208, 0.0000, 0.6102, 0.6190],
        [0.4574, 0.6340, 0.6102, 0.0000, 0.6412],
        [0.4520, 0.6040, 0.6190, 0.6412, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 94 total loss 0.16152155776217114 0.00016948746879556258
epoch 95 total loss 0.16183714685229234 0.0001698186220905481
aida-A micro F1: 0.9193194864836656
aida-B micro F1: 0.9328874024526198
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8755244755244754
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7737154150197629
wikipedia micro F1: 0.7799718955698544
att_mat_diag tensor(17.3285, device='cuda:0')
tok_score_mat_diag tensor(17.2457, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.2570, device='cuda:0') tensor(1.4743, device='cuda:0')
relations tensor([20.6409,  3.9292,  3.9180,  3.9095,  3.9431], device='cuda:0')
tensor([[0.0000, 0.6763, 0.7025, 0.7027, 0.6909],
        [0.6763, 0.0000, 0.2008, 0.2043, 0.1942],
        [0.7025, 0.2008, 0.0000, 0.1947, 0.2146],
        [0.7027, 0.2043, 0.1947, 0.0000, 0.2053],
        [0.6909, 0.1942, 0.2146, 0.2053, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.0285, 7.8854, 7.8401, 7.7523, 7.9256], device='cuda:0')
tensor([[0.0000, 0.4311, 0.4394, 0.4567, 0.4512],
        [0.4311, 0.0000, 0.6197, 0.6328, 0.6029],
        [0.4394, 0.6197, 0.0000, 0.6091, 0.6178],
        [0.4567, 0.6328, 0.6091, 0.0000, 0.6401],
        [0.4512, 0.6029, 0.6178, 0.6401, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 96 total loss 0.16073286992036628 0.00016865988449146514
epoch 97 total loss 0.16107595847773837 0.00016901989347086922
aida-A micro F1: 0.9197369794384719
aida-B micro F1: 0.9342251950947603
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8839160839160839
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7770391663672296
wikipedia micro F1: 0.7792323053028622
att_mat_diag tensor(17.3273, device='cuda:0')
tok_score_mat_diag tensor(17.2419, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.3110, device='cuda:0') tensor(1.4726, device='cuda:0')
relations tensor([20.6451,  3.9338,  3.9226,  3.9141,  3.9478], device='cuda:0')
tensor([[0.0000, 0.6767, 0.7030, 0.7033, 0.6914],
        [0.6767, 0.0000, 0.2010, 0.2046, 0.1944],
        [0.7030, 0.2010, 0.0000, 0.1949, 0.2149],
        [0.7033, 0.2046, 0.1949, 0.0000, 0.2055],
        [0.6914, 0.1944, 0.2149, 0.2055, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.0601, 7.9146, 7.8681, 7.7811, 7.9540], device='cuda:0')
tensor([[0.0000, 0.4303, 0.4386, 0.4559, 0.4504],
        [0.4303, 0.0000, 0.6185, 0.6317, 0.6018],
        [0.4386, 0.6185, 0.0000, 0.6080, 0.6167],
        [0.4559, 0.6317, 0.6080, 0.0000, 0.6389],
        [0.4504, 0.6018, 0.6167, 0.6389, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 98 total loss 0.16084522607178542 0.0001687777818171935
epoch 99 total loss 0.160685651498909 0.000168610337354574
aida-A micro F1: 0.9193194864836656
aida-B micro F1: 0.934448160535117
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8783216783216785
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7749730506647503
wikipedia micro F1: 0.7799718955698544
att_mat_diag tensor(17.3265, device='cuda:0')
tok_score_mat_diag tensor(17.2381, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.3630, device='cuda:0') tensor(1.4734, device='cuda:0')
relations tensor([20.6487,  3.9386,  3.9275,  3.9189,  3.9526], device='cuda:0')
tensor([[0.0000, 0.6773, 0.7037, 0.7040, 0.6920],
        [0.6773, 0.0000, 0.2012, 0.2048, 0.1945],
        [0.7037, 0.2012, 0.0000, 0.1951, 0.2151],
        [0.7040, 0.2048, 0.1951, 0.0000, 0.2056],
        [0.6920, 0.1945, 0.2151, 0.2056, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.0905, 7.9422, 7.8949, 7.8080, 7.9811], device='cuda:0')
tensor([[0.0000, 0.4296, 0.4379, 0.4553, 0.4497],
        [0.4296, 0.0000, 0.6175, 0.6306, 0.6008],
        [0.4379, 0.6175, 0.0000, 0.6070, 0.6156],
        [0.4553, 0.6306, 0.6070, 0.0000, 0.6379],
        [0.4497, 0.6008, 0.6156, 0.6379, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 100 total loss 0.15947737605227985 0.0001673424722479327
epoch 101 total loss 0.15881782359286944 0.0001666503920177014
aida-A micro F1: 0.9197369794384719
aida-B micro F1: 0.9324414715719064
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8895104895104895
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.7799137621272008
wikipedia micro F1: 0.7784927150358701
att_mat_diag tensor(17.3265, device='cuda:0')
tok_score_mat_diag tensor(17.2341, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.4154, device='cuda:0') tensor(1.4733, device='cuda:0')
relations tensor([20.6528,  3.9435,  3.9323,  3.9236,  3.9574], device='cuda:0')
tensor([[0.0000, 0.6778, 0.7042, 0.7046, 0.6926],
        [0.6778, 0.0000, 0.2014, 0.2050, 0.1947],
        [0.7042, 0.2014, 0.0000, 0.1953, 0.2153],
        [0.7046, 0.2050, 0.1953, 0.0000, 0.2058],
        [0.6926, 0.1947, 0.2153, 0.2058, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.1212, 7.9699, 7.9216, 7.8346, 8.0077], device='cuda:0')
tensor([[0.0000, 0.4289, 0.4372, 0.4547, 0.4491],
        [0.4289, 0.0000, 0.6165, 0.6295, 0.5999],
        [0.4372, 0.6165, 0.0000, 0.6061, 0.6146],
        [0.4547, 0.6295, 0.6061, 0.0000, 0.6370],
        [0.4491, 0.5999, 0.6146, 0.6370, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 102 total loss 0.15784244157310923 0.00016562690616275889
epoch 103 total loss 0.15888616786156717 0.00016672210688517018
aida-A micro F1: 0.9197369794384719
aida-B micro F1: 0.9342251950947603
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8783216783216785
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7745238950772547
wikipedia micro F1: 0.7804156497300495
att_mat_diag tensor(17.3260, device='cuda:0')
tok_score_mat_diag tensor(17.2308, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.4678, device='cuda:0') tensor(1.4735, device='cuda:0')
relations tensor([20.6566,  3.9480,  3.9368,  3.9281,  3.9619], device='cuda:0')
tensor([[0.0000, 0.6783, 0.7047, 0.7052, 0.6931],
        [0.6783, 0.0000, 0.2016, 0.2053, 0.1949],
        [0.7047, 0.2016, 0.0000, 0.1955, 0.2155],
        [0.7052, 0.2053, 0.1955, 0.0000, 0.2060],
        [0.6931, 0.1949, 0.2155, 0.2060, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.1500, 7.9961, 7.9473, 7.8601, 8.0332], device='cuda:0')
tensor([[0.0000, 0.4283, 0.4367, 0.4541, 0.4485],
        [0.4283, 0.0000, 0.6155, 0.6286, 0.5990],
        [0.4367, 0.6155, 0.0000, 0.6052, 0.6136],
        [0.4541, 0.6286, 0.6052, 0.0000, 0.6360],
        [0.4485, 0.5990, 0.6136, 0.6360, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 104 total loss 0.15745357306622054 0.00016521885946088198
epoch 105 total loss 0.15728955902767439 0.00016504675658727638
aida-A micro F1: 0.9207807118254878
aida-B micro F1: 0.9340022296544036
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8839160839160839
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7771289974847286
wikipedia micro F1: 0.7784927150358701
att_mat_diag tensor(17.3255, device='cuda:0')
tok_score_mat_diag tensor(17.2269, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.5200, device='cuda:0') tensor(1.4721, device='cuda:0')
relations tensor([20.6606,  3.9529,  3.9417,  3.9329,  3.9667], device='cuda:0')
tensor([[0.0000, 0.6788, 0.7053, 0.7058, 0.6937],
        [0.6788, 0.0000, 0.2018, 0.2055, 0.1951],
        [0.7053, 0.2018, 0.0000, 0.1957, 0.2157],
        [0.7058, 0.2055, 0.1957, 0.0000, 0.2062],
        [0.6937, 0.1951, 0.2157, 0.2062, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.1809, 8.0245, 7.9742, 7.8876, 8.0611], device='cuda:0')
tensor([[0.0000, 0.4276, 0.4360, 0.4535, 0.4478],
        [0.4276, 0.0000, 0.6145, 0.6275, 0.5980],
        [0.4360, 0.6145, 0.0000, 0.6041, 0.6126],
        [0.4535, 0.6275, 0.6041, 0.0000, 0.6350],
        [0.4478, 0.5980, 0.6126, 0.6350, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 106 total loss 0.15618244118599023 0.00016388503797060884
epoch 107 total loss 0.15782965061691812 0.00016561348438291513
aida-A micro F1: 0.9195282329610688
aida-B micro F1: 0.9317725752508361
msnbc micro F1: 0.9395562356541699
aquaint micro F1: 0.8895104895104895
ace2004 micro F1: 0.9054325955734406
clueweb micro F1: 0.780093424362199
wikipedia micro F1: 0.7776052067154796
att_mat_diag tensor(17.3249, device='cuda:0')
tok_score_mat_diag tensor(17.2233, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.5694, device='cuda:0') tensor(1.4701, device='cuda:0')
relations tensor([20.6642,  3.9572,  3.9462,  3.9374,  3.9711], device='cuda:0')
tensor([[0.0000, 0.6793, 0.7059, 0.7064, 0.6943],
        [0.6793, 0.0000, 0.2020, 0.2057, 0.1953],
        [0.7059, 0.2020, 0.0000, 0.1960, 0.2159],
        [0.7064, 0.2057, 0.1960, 0.0000, 0.2064],
        [0.6943, 0.1953, 0.2159, 0.2064, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.2099, 8.0505, 7.9997, 7.9133, 8.0869], device='cuda:0')
tensor([[0.0000, 0.4270, 0.4354, 0.4528, 0.4472],
        [0.4270, 0.0000, 0.6136, 0.6266, 0.5971],
        [0.4354, 0.6136, 0.0000, 0.6033, 0.6116],
        [0.4528, 0.6266, 0.6033, 0.0000, 0.6341],
        [0.4472, 0.5971, 0.6116, 0.6341, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 108 total loss 0.157332262521777 0.00016509156612988144
epoch 109 total loss 0.1558260834307248 0.00016351110538376159
aida-A micro F1: 0.9205719653480847
aida-B micro F1: 0.9337792642140468
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8839160839160839
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7774883219547252
wikipedia micro F1: 0.7790843872494637
att_mat_diag tensor(17.3246, device='cuda:0')
tok_score_mat_diag tensor(17.2198, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.6186, device='cuda:0') tensor(1.4703, device='cuda:0')
relations tensor([20.6688,  3.9627,  3.9516,  3.9427,  3.9764], device='cuda:0')
tensor([[0.0000, 0.6797, 0.7063, 0.7069, 0.6947],
        [0.6797, 0.0000, 0.2022, 0.2059, 0.1954],
        [0.7063, 0.2022, 0.0000, 0.1961, 0.2161],
        [0.7069, 0.2059, 0.1961, 0.0000, 0.2066],
        [0.6947, 0.1954, 0.2161, 0.2066, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.2394, 8.0774, 8.0255, 7.9397, 8.1133], device='cuda:0')
tensor([[0.0000, 0.4263, 0.4347, 0.4522, 0.4466],
        [0.4263, 0.0000, 0.6126, 0.6256, 0.5962],
        [0.4347, 0.6126, 0.0000, 0.6023, 0.6107],
        [0.4522, 0.6256, 0.6023, 0.0000, 0.6332],
        [0.4466, 0.5962, 0.6107, 0.6332, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 110 total loss 0.15561714903037682 0.00016329186676849615
epoch 111 total loss 0.15556788687109702 0.00016324017510083633
aida-A micro F1: 0.9205719653480847
aida-B micro F1: 0.9346711259754737
msnbc micro F1: 0.938026013771997
aquaint micro F1: 0.8825174825174825
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7751527128997485
wikipedia micro F1: 0.7805635677834479
att_mat_diag tensor(17.3241, device='cuda:0')
tok_score_mat_diag tensor(17.2160, device='cuda:0')
f - l1.w, b tensor(6.0453, device='cuda:0') tensor(3.9130, device='cuda:0')
f - l2.w, b tensor(0.5641, device='cuda:0') tensor(0.0256, device='cuda:0')
tensor(30.6696, device='cuda:0') tensor(1.4694, device='cuda:0')
relations tensor([20.6725,  3.9673,  3.9563,  3.9473,  3.9811], device='cuda:0')
tensor([[0.0000, 0.6803, 0.7069, 0.7075, 0.6953],
        [0.6803, 0.0000, 0.2024, 0.2062, 0.1956],
        [0.7069, 0.2024, 0.0000, 0.1964, 0.2163],
        [0.7075, 0.2062, 0.1964, 0.0000, 0.2068],
        [0.6953, 0.1956, 0.2163, 0.2068, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
ew_embs tensor([9.2694, 8.1050, 8.0521, 7.9665, 8.1403], device='cuda:0')
tensor([[0.0000, 0.4256, 0.4340, 0.4516, 0.4459],
        [0.4256, 0.0000, 0.6116, 0.6246, 0.5953],
        [0.4340, 0.6116, 0.0000, 0.6014, 0.6097],
        [0.4516, 0.6246, 0.6014, 0.0000, 0.6322],
        [0.4459, 0.5953, 0.6097, 0.6322, 0.0000]], device='cuda:0',
       grad_fn=<SqrtBackward>)
epoch 112 total loss 0.15537055669062738 0.00016303311300170764
epoch 113 total loss 0.1549516468010097 0.00016259354333789057
aida-A micro F1: 0.9189019935288592
aida-B micro F1: 0.9348940914158306
msnbc micro F1: 0.936495791889824
aquaint micro F1: 0.8713286713286713
ace2004 micro F1: 0.9014084507042254
clueweb micro F1: 0.7726374416097738
wikipedia micro F1: 0.7805635677834479
